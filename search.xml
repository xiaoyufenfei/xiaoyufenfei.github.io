<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ICIP2019-难忘的台湾之行]]></title>
    <url>%2F2019%2F09%2F27%2Ficip2019-nan-wang-de-tai-wan-zhi-xing%2F</url>
    <content type="text"><![CDATA[### ICIP 2019 : IEEE International Conference on Image Processing 从投稿 IEEE ICIP 到中稿 ICIP Oral，再到顺利拿到入台的批件，终于在9.21日开始了台湾之行，这篇博文用来记录在台北一周的见闻。 第26届IEEE国际图像处理会议（ICIP）顺利在台湾台北国际会议中心举行，ICIP是世界上规模最大，最全面的技术会议，重点是图像、视频处理和计算机视觉，会议包括了特邀主旨演讲，Oral Session，Poster Session以及行业展示等等… 9.22号上午去注册，和国内相比，并没有采用人脸识别签到，速度较慢，所以排队签到。领到了参会牌子、带有ICIP Logo的纪念帽和Tshirt、以及ICIP定制的SWISSGEAR双肩包、多功能转换插座、已充值的交通悠游卡、U盘等等，早知道那么贴心，有些东西就不提前买了😄 和我同行的是同班级同学，一块组团过来参会了，拍照留念，这次能出来参会真的不容易。。。 好不容易来一趟，多在台北转转吧。。。😂 西门町 西门町, 台北著名的流行商圈、最具特色徒步区，是台北第一条专为行人设置的区域，红楼、刺青街、电影街、KTV、万年大楼、万国百货、诚品书店和各式各样的精品小店都可以在西门町看到，是台北民众假日最喜爱的去处之一 西门町，感觉真心不错，虽然没有南京新街口的气韵，它的独特风格即是潮！许多网红店在那边，走走看看停停，很惬意啊！西门町是青年文化胜地，也是台北最具特色的徒步区。杂志、游戏机、化妆品、潮牌潮衣、玩具模型等应有尽有。西门町特色小吃店众多，鸭肉扁、阿宗面线、老天禄卤味等远近驰名。街上时常会有艺人弹唱或特色活动。 松山文创园松山文创园离国父纪念馆很近。既然是创意园区，所以是以文化为主打。没有了游客的熙熙攘攘，也没有商业化气息很浓，可以让你有机会细细的品味。建议在台北无论是松山还是华山创园区都是值得花半天时间来细细品味的。。。 台北故宫博物院 台北故宫博物院是中国著名的历史与文化艺术史博物馆，坐落在台北市基隆河北岸士林区外双溪，依山傍水，气势宏伟，碧瓦黄墙。院前广场耸立由6根石柱组成的牌坊，气势宏伟，整座建筑庄重典雅，富有民族特色。院内设有20余间展览室，文化瑰宝不胜枚举。院内收藏有自北京故宫博物院、南京国立中央博物院、沈阳故宫、热河行宫、中国青铜器之乡-宝鸡运到台湾的二十四万余件文物。 台北故宫博物院的馆藏丰富，翠玉白菜、肉形石、毛公鼎、甲骨档案、陶瓷铜器、古代书画、善本古籍……太多太多的精品，目不暇接。 台北101摩天大楼101大楼就在我们开会的地点台北国际会议中心附近，听司机说没什么可看的，我们也就没买票上去看看，就在外面转了转… 101大楼是台湾最高的一座建筑，高500多米，建筑在地上有101层，地下有5层。只可惜晚上我们要参加Banquet，就没时间了。如果真的要观景的话，日落前到达一直游览到天黑，夜景会很漂亮，可以在高处尽情地欣赏台北的全景。101大楼门票差不多500新台币，合人民币100左右。 台北圆山大饭店大会Banquet晚宴设在了这里，圆山大饭店建筑恢弘大气，就像一座大宫殿。酒店非常有特色，很大，1952建造保存的很好 ，员工服务好。。。 碰到了大佬 Yann LeCun，美国工程院院士、Facebook人工智能研究院院长、纽约大学Sliver教授… 饶河街夜市最后一天下午参会后，到饶河街夜市转了一圈。 饶河街夜市位于台北松山区，紧邻着松山慈祐宫，是台北的庶民饮食、购物天堂。交通极其便利，驱车前往台北101仅15分钟，离松山火车站也就600米距离。每到周末假日，这里必定人潮汹涌，其中不少是慕名而来的游客。夜幕降临，夜市街道上空挂着的灯饰就会点亮，灯火辉煌。道路中间有两排摊位，两侧则是整排的店面。整个夜市分布着数百家摊店，不管是豆花、蚵仔面线、药燉排骨，还是土耳其特色冰淇淋都应有尽有。除了夜市必有的美食，这里还有许多服饰商店，从帽子、鞋子到包包，甚至连抓娃娃机和各种算命摊小摊都可以在此找到，真是摊位齐全啊！ IEEE ICIP 2019 Oral Session说了那么多玩的啊😂，其实来台北主要还是参加ICIP2019大会的，很荣幸的论文被选为了Oral，于分会场作20min发言，包括提问环节。还好，不是太紧张… PPT首页和末页： 总结此次台湾之行，虽然没有大玩，但也了解了台湾这边的文化生活、风土人情等，蛮开心的一次会议出行计划，台湾，再会！ 拿着实验室的资助来参会，非常感谢导师，正如导师寄语，课题组每个研究生，都应该至少参加一次国际会议。算起来继8月份去韩国参加国际会议后，这是我第二次出国/境开会，倍感荣幸，见到不一样的人，听到不一样的研究，你的眼界就不一样了，看事物的方式也不一样了。 最后还是祝自己2019年顺利吧，希望找工作顺利，毕业顺利，最后碰到一个有缘人吧。 也希望课题组的学弟学妹们加油 💪]]></content>
      <categories>
        <category>参加国际会议</category>
      </categories>
      <tags>
        <tag>参加国际会议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[How to read a paper]]></title>
    <url>%2F2019%2F09%2F13%2Fhow-to-read-a-paper%2F</url>
    <content type="text"><![CDATA[作研究要花费大量时间在阅读论文上📕。但是这个技能却很少人教，这就导致大量时间被浪费。最近发现一篇paper，教人如何阅读paper，所以记录如下，与君共勉！！！ 重要性 在field内保持先进性，keep up the trend 获得灵感 review 方法论作者总结出了three-pass 方法。顾名思义，就是阅读一篇paper三遍，每一遍分别有不同的侧重点。 general idea content，but not details understand the paper in depth 第一遍这一遍快速扫描，用来决定是否需要继续深入读下去。 时间 5-10 min 内容 title, abstract, introduction 只看section &amp; subsection headings conclusion 扫一眼reference，排除掉看过的那些paper 目标看完这一遍要能够回答： 类别：这篇论文是哪一个类别的？ 是提出了一个新方法、还是实际分析、或是提出了一个模型？ 基于什么理论基础？ 是否valid？包括假设是否合理、逻辑是否合理等。 主要贡献？ 写的清晰么？ 作用第一遍读完之后，可能你会选择放弃这篇paper。这可能是因为你对论文不感兴趣，或者是你对该领域的了解不足以看懂论文，或者作者做出了无效的假设。 只阅读一遍的论文，适用于阅读不在您研究领域内的论文，可能会给你启发。 启发注意！但你知道如何读第一遍论文的时候，也要想到反过来，reviewer在读你的论文的时候会如何想。因为大多数reviewer只会读它一次。 所以，注意选择连贯的section &amp; subsection headings，并撰写简洁而全面的摘要。 如果审稿人在一次通读后无法理解要点，那么该论文可能会被拒绝; 如果读者在五分钟后无法理解论文的亮点，那么论文可能永远不会被阅读。 第二遍第二遍需要读更仔细，但是忽略掉细节，如证明过程。 圈出或写下关键词会有帮助。 内容 figure、diagrams、或者其他图表 标记出reference中没有阅读过的paper，这对background的扩展是一个帮助 时间 &lt;= 1小时 目标 能够列举文章的几个主要观点，及其支持的论据 作用有时候读完第二遍仍然无法理解，那么可能是因为： 你不熟悉这个subject （课题），有很多术语无法理解 作者所用的技术、方法你无法理解 作者写的不好 你太累了 那么现在可以选择： 放一边，祈祷你职业生涯的成功与它无关 看完reference 再来看它 开始第三遍 第三遍第三遍的时候，随着作者的逻辑，与作者一起假装完成一次推理/实现过程。这一遍要重点关注细节，把每一个statement中暗藏的假设都找出来。并且，还要时刻问自己，如果是自己写/做这一步，会如何做？这也能给future work提供想法。 时间 初学者：4-5小时 熟练工：1小时 目标 能够重构整篇paper的结构 能够说出它的优缺点 最好能够找出它缺少了什么标准、相关工作，或实验、分析技术中可能出现的问题 如何做survey为了深入一个领域，我们往往需要做某个specific方向的survey。 那么如何做呢？作者也提供了一个很好的三步走思路。 第一步 善用搜索引擎Google scholar 好用的谷歌学术网址 DBLP computer science bibliography 、computer science bibliography CiteSeerX NEC研究院学术论文 搜索关键词，找出最近的3-5篇paper 用第一遍阅读法阅读它们，并阅读它们的related work部分。如果幸运的话，通过它们，可能就能找到最近的一篇survey，那么就不用自己做survey了～ 第二步 找出大佬找出以上的论文中重复的引用（key paper）、频繁出现的名字(大佬)。下载key papers，并在搜索引擎中搜索大佬们近期的文章。看看这些文章一般发表在什么conference上。为什么要看这些conference呢？因为大佬们的文章一般只会发在top conference上，这能帮你很快找出该领域的顶会。 第三步 利用会议找出高质量文章通过刚刚找出的顶会，查看最近几年发表的论文中相关的论文。这些高质量的论文+ 第二步中找到的那些key paper， 能帮你快速建立你的第一版survey。 重复上述过程一遍，作为论文补充。 最后，学会看 arXiv才能不错过自己研究领域的最新进展arXiv论文怎样读？ AI领域：如何做优秀研究并写高水平论文？周志华教授《做研究与写论文》的PPT(时间比较早，但方法永远不会过时)。其详细介绍了关于为什么要做研究？如何做研究，选择研究方向、选择研究课题(Topic)，学习领域知识、选期刊投稿、稿件处理过程、写高水平论文的方法与技巧等方面的知识，是一份非常优秀的做研究和写论文指南，值得每个人细读 ★★★★★ 周志华教授简介 他于2001年1月留校任教，2002年破格晋升副教授，2003年获 国家杰出青年科学基金，随后被聘任为教授，2004年获博士生导师资格，2006年入选教育部长江学者特聘教授。现任南京大学 校学术委员会委员、计算机科学与技术系 主任、人工智能学院 院长，主要从事人工智能、机器学习、数据挖掘等领域的研究工作。主持多项科研课题，出版《机器学习》(2016)、《Ensemble Methods: Foundations and Algorithms》(2012)、《Evolutionary Learning: Advances in Theories and Algorithms》(2019)。 周教授主页：https://cs.nju.edu.cn/zhouzh/ 原文PDF下载链接 https://pan.baidu.com/s/17Mq8y7DFRoY7sGESF9vZhQ 提取码: nmvk 他山之石 文章来源: how-to-read-a-paper]]></content>
      <categories>
        <category>科研工具</category>
      </categories>
      <tags>
        <tag>科研工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Latex撰写论文常用技巧总结]]></title>
    <url>%2F2019%2F09%2F12%2Flatex-zhuan-xie-lun-wen-chang-yong-ji-qiao-zong-jie%2F</url>
    <content type="text"><![CDATA[写论文不得不时常与Latex打交道，这篇博文专门用来记录使用Latex撰写论文过程中遇到的一些技巧与心得。 使用环境：online overleaf (https://www.overleaf.com/) Overleaf是一个在线latex环境，有许多模版可以选择，还可以上传已有的latex文件夹（zip），很方便。 推荐指数：🌟🌟🌟🌟🌟 同类替代：sharelatex (https://cn.sharelatex.com/) 目前网上大部分人习惯TeX Live加编辑器的环境配置模式。尽管依旧有很多人在使用CTeX加WinEdit，但CTeX已经有很久没有更新，所以大家：千万不要装CTeX套装！！ LaTeX安装配置参考 LaTeX安装资料合集 详细安装配图说明 LaTex开源小屋软件下载 1.如何引用参考文献1.1写bib文件 Google Scholar 搜索需要引用的论文标题 好用的谷歌学术网址 输入文献名之后，在搜索结果中点引用： 点击上图中的空心双引号，就会弹出这个窗口。选择想要的bib格式进行复制 1.2新建bib文件新建以.bib结尾的引用文件，并把刚刚复制的文献信息粘贴在文件中 @article{ferrari2006raman, %此处为引用标签 title={Raman spectrum of graphene and graphene layers}, author={Ferrari, Andrea C and Meyer, JC and Scardaci, V and Casiraghi, C and Lazzeri, Michele and Mauri, Francesco and Piscanec, S and Jiang, Da and Novoselov, KS and Roth, S and others}, journal={Physical review letters}, volume={97}, number={18}, pages={187401}, year={2006}, publisher={APS} } 1.3在正文中链接到bib文件为了更有条理地管理latex文档，所以比较习惯把整个latex文档分成3部分： 包管理、标题、自定义环境、变量等； 正文部分； 引用文献； 1.4在正文中进行引用以上图bib文件中的第一篇paper为例，如果要引用它，则： we cite a paper here \cite{ferrari2006raman}. 2.公式录入 免费数学神器Mathpix，强大到出移动版了，手写公式扫一扫就能识别，一键嵌入 MarkDown。 公式编辑器-知乎 博文分享 下载地址：https://mathpix.com/ 3.表格处理表格处理工具：LaTeX Tables Generator 4.制作幻灯片没错，LaTeX的确还可以制作精美的幻灯片pdf，不过具体使用方法与论文写作大同小异，网上也有很多漂亮的模板，有兴趣可以去继续了解。 LaTex Beam主题模板 5.插入矢量图片PDF工具就用它了Adobe Acrobat 👍 , 包揽你常用的PDF内容编辑，页面裁剪，导出，生成PDF等多项功能！！ Adobe Acrobat安装 总结日常写作用轻量级的Markdown编辑器 typora, 主页极其漂亮的同时，软件本身也非常简洁实用，功能强大。想要获得更为复杂和严谨的论文排版作品，上LaTeX，这样基本就能涵盖所有的写作场景，告别臃肿难用的word软件，让我们更专注于内容，享受其中。 暂时就想到这些了，等想到了再更吧，Happy LaTeXing！]]></content>
      <categories>
        <category>软件安装与配置</category>
      </categories>
      <tags>
        <tag>软件安装与配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通道注意力机制-SENet]]></title>
    <url>%2F2019%2F09%2F11%2Ftong-dao-zhu-yi-li-ji-zhi-senet%2F</url>
    <content type="text"><![CDATA[SENetarXiv-Link： Squeeze-and-Excitation NetworksJie Hu, Li Shen, Gang Sun 摘要卷积神经网络顾名思义就是依赖卷积操作，使用局部感受区域（local receptive field）的思想融合空间信息和通道信息来提取包含信息的特征。有很多工作从增强空间维度编码的角度来提升网络的表示能力，本文主要聚焦于通道维度，并提出一种新的结构单元——“Squeeze-and-Excitation(SE)”单元，对通道间的依赖关系进行建模，可以自适应的调整各通道的特征响应值。如果将SE block添加到之前的先进网络中，只会增加很小的计算消耗，但却可以极大地提升网络性能。依靠SENet作者获得了ILSVRC2017分类任务的第一名，top-5错误率为2.251%。 1. Introduction每个卷积层有若干滤波器，可以学习表达包含所有通道的局部空间连接模式。也就是说，卷积滤波器提取局部感受区域中的空间和通道的融合信息。再加上非线性激活层和降采样层，CNN可以获得具有全局感受区域的分层模式来作为图像的描述。最近的一些工作表明，可以通过加入有助于获取空间相关性的学习机制来改善网络的性能，而且不需要额外的监督。例如Inception架构，通过在模块中加入多尺度处理来提高性能。另有探索更好的空间相关性的模型或者添加空间注意力的一些工作。 与上述方法不同，本文主要探索网络架构设计的另一个方面——通道关联性。本文提出一种新的网络单元——“Squeeze-and-Excitation(SE)” block，希望通过对各通道的依赖性进行建模以提高网络的表示能力，并且可以对特征进行逐通道调整，这样网络就可以学习通过全局信息来有选择性的加强包含有用信息的特征并抑制无用特征。SE block的基本结构见图1。第一步squeeze操作，将各通道的全局空间特征作为该通道的表示，形成一个通道描述符；第二步excitation操作，学习对各通道的依赖程度，并根据依赖程度的不同对特征图进行调整，调整后的特征图就是SE block的输出。 前面层中的SE block以类别无关（class agnostic）的方式增强可共享的低层表示的质量。越后面的层SE block越来越类别相关。SE block重新调整特征的益处可以在整个网络中积累。SE block设计简单，可以很容易地加入到已有的网络中，只增加少量的模型复杂度和计算开支，另外对不同数据集的泛化能力较强。作者依靠SENet取得了ILSVRC2017分类任务的第一名。官方实现（Caffe）源码地址：SENet官方实现 。 2. Related WorkDeep architectures有很多工作通过调整卷积神经网络架构使模型更容易地学习深层特征以提升模型性能。VGG和Inception网络证明可以通过增加深度来提升性能。Batch normalization (BN)在网络中添加可以调节输入数据的单元来稳定学习过程，改善梯度在网络中的传播，使得更深层的网络也可以工作。ResNet、ResNet-v2在网络中加入恒等映射形式的跳跃连接，使网络学习残差函数，极大推进了网络架构向更深层的发展。DenseNet、DPN通过调整网络各层间的连接机制来提升深层网络的学习和表示性能。另一个方向是调整网络中模块的形式。分组卷积（grouped convolutions）可以用于增加基数（cardinality），如Deep roots、ResNeXt中所示，网络可以学习到更丰富的表示。多分支卷积（multi-branch convolutions）可以视为分组卷积的泛化，网络模块可以进行更灵活多变的操作，如Inception系列。跨通道相关是一种新的特征组合方式，可以独立于空间结构（如Xception），或者使用1x1卷积进行处理（如NIN），一般来说这些工作主要是为了降低模型和计算复杂度。这种方法的前提假设是通道是实例无关（instance-agnostic）的，也就是说输出对于输入数据各通道的依赖性是相同的，不是类别相关的。与之相反，本文提出一种新的机制，使用全局信息对各通道动态的非线性的依赖性进行建模，可以改善学习过程并提升网络的表示能力。 Attention and gating mechanisms注意力机制（attention）引导计算资源偏向输入信号中信息量最大的部分，近几年开始大量用于深度神经网络中，在很多任务中对性能有极大提升。它一般是和门限函数（如softmax、sigmoid）或者序列方法联合使用。highway网络使用门限机制来调节快捷连接，Residual attention network for image classification中介绍了一种trunk-and-mask注意力机制用于沙漏模型（hourglass module），成功的用于语义分割任务。SE block是一种轻量级的门限机制，专门用于对各通道的关联性进行建模。 3. Squeeze-and-Excitation Blocks卷积层的输出并没有考虑对各通道的依赖性，本文的目标就是让网络有选择性的增强信息量大的特征，使得后续处理可以充分利用这些特征，并对无用特征进行抑制。 3.1 Squeeze: Global Information Embedding首先考察输出特征每个通道的信号，压缩（squeeze）全局空间信息为通道描述符，使用全局平均池化来生成各通道的统计量。 3.2 Excitation: Adaptive Recalibration第二就是考察各通道的依赖程度，实现函数有两个标准：一是要灵活，二是要学习一个非互斥的关系，因为可能多个通道都会对结果有影响。本文使用带sigmoid激活函数的门限机制来实现。为了限制模型复杂度并增强泛化能力，门限机制中使用bottleneck形式的两个全连接层，第一个FC层降维至1/r，r为超参数，本文取16，具体见6.3实验。最后的sigmoid函数就是各通道的权重，根据输入数据调节各通道特征的权重，有助于增强特征的可分辨性。 3.3 Exemplars: SE-Inception and SE-ResNet在Inception网络和ResNet网络中加入SE block，具体见图2、图3。 4. Model and Computational Complexity对添加了SE block的网络的具体配置见表1。 每个SE block中包含一个全局平均池化操作，两个小的全连接层，最后一个简单的逐通道缩放操作，全部合起来在ResNet-50的基础上增加了0.26%的计算量。新添加的参数量主要来自于两个全连接层，ResNet-50增加了约10%，大多数都是来自最后阶段，此时的通道维度很大。但是实验发现如果去掉最后阶段的SE block性能并没有太大影响，而新增加的参数量则会减小到约4%。 5. Implementation基本都是常规处理和训练设置。采用了Relay backpropagation for effective learning of deep convolutional neural networks中的数据平衡策略。 6. Experiments6.1 ImageNet Classification本文实验的不同网络的配置见表2，训练曲线见图4-6。 在ImageNet验证集上不同网络的表现见表3。 6.2 Scene Classification不同网络的性能对比见表4。 6.3 Analysis and DiscussionReduction ratio3.2中讨论的降维系数是超参数，它不同取值对网络性能的影响见表5。 为了权衡准确率与复杂度，本文选取r=16。The role of Excitation考察自门限（self-gating）excitation机制。选取四个类别（如图7），分别考察不同层中的SE block的平均激活值，其分布如图8所示。 通过观察图8中不同层SE block激活值的分布情况，发现1)前面层中的分布基本一样，说明这一阶段的特征是类别无关的；2)后续层中分布越来越类别相关，每个类别对特征由不同的选择；3)SE_5_2和SE_5_3中的分布也基本一致，说明这两层对网络重新调整的重要性不高，可以去掉这两层中的SE block以减少参数量，如第4章中所述。 7. ConclusionSE block根据输入动态调整各通道的特征，增强网络的表示能力。另外也可以用于辅助网络修剪/压缩的工作。]]></content>
      <categories>
        <category>Paper Reading</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习GPU环境搭建-下篇]]></title>
    <url>%2F2019%2F09%2F11%2Fshen-du-xue-xi-gpu-huan-jing-da-jian-xia-pian%2F</url>
    <content type="text"><![CDATA[本节详细说明一下最新GPU深度学习平台环境配置 Ubuntu16+RTX2080Ti+CUDA10+Python3.6+Pytorch1.2 服务器环境Ubuntu: 16.04 64bit Nvidia driver 410 Anaconda: 3 python3.6 CUDA: 10.0 cuDNN: 7.4 1.安装Linux系统需要从网上下载ubuntu系统，并制作安装U盘。 准备工作。制作Ubuntu系统启动U盘，可参考链接 U盘启动安装，开机按delete或f2进入BIOS，更改启动方式，U盘启动 进入ubuntun选择试用不安装，进入之前的unbuntun系统，备份home盘数据（如果不备份，重装系统数据会清除）。 U盘启动，选择install unbuntun. 选择英文，图形界面不勾选，installtion type 选择 something else。 注：如果是安装双系统，不要选择第二项 擦除数据，这会把之前系统盘文件全部删除。参考博客https://blog.csdn.net/fesdgasdgasdg/article/details/54183577?tdsourcetag=s_pcqq_aiomsg 进入unbuntun系统，图形分辨率字很大，不用担心，因为没安装显卡驱动原因。安装对应显卡驱动 安装完显卡驱动，你将拥有全新的unbuntun系统，则可以进行你常用的环境配置与软件安装，以自身需求，介绍一下要用到的深度学习环境和常用软件安装。安装常用软件 谷歌浏览器，搜狗输入法，notepad++, 为知笔记，pycharm, anaconda, cuda,opencv pytorch tensorflow 配置VPN，teamviewer 等。cuda+cudnn,参考链接https://blog.csdn.net/gdengden/article/details/89399653 2.安装英伟达NVIDIA驱动1.禁用nouveau 安装NVIDIA需要把系统自带的驱动禁用，打开文件： sudo vim /etc/modprobe.d/blacklist.conf 在文本最后添加以下内容： blacklist nouveau options nouveau modeset=0 命令窗口会提示warning，忽略即可。保存退出，执行以下命令生效： sudo update-initramfs -u 重启后，执行以下命令： lsmod | grep nouveau 如果没有屏幕输出，说明禁用nouveau成功 2.下载驱动文件 安装好linux系统后，对于RTX2080ti来说，Nvidia driver 384已经不适合了，请从官方网站下载和自己的显卡适配的驱动文件，是.run文件，下载地址:Download Drivers 下载完成之后会得到一个安装包，不同版本文件名可能不一样： NVIDIA-Linux-x86_64-410.93.run 3.卸载原有的NVIDIA驱动（没装的话就跳过第3步） 操作都需要在命令界面操作，执行以下快捷键进入命令界面，并登录： Ctrl-Alt+F1 执行以下命令禁用X-Window服务，否则无法安装显卡驱动： sudo service lightdm stop 执行以下三条命令卸载原有显卡驱动： sudo apt-get remove --purge nvidia* sudo chmod +x NVIDIA-Linux-x86_64-410.93.run sudo ./NVIDIA-Linux-x86_64-410.93.run --uninstall 4.安装新驱动 直接执行驱动文件即可安装新驱动，一直默认即可： sudo ./NVIDIA-Linux-x86_64-410.93.run 执行以下命令启动X-Window服务: sudo service lightdm start 最后执行重启命令，重启系统即可： reboot 安装完成后，查看驱动版本： sudo dpkg --list | grep nvidia-* nvidia-smi 不出意外说明显卡驱动成功安装，后面继续安装cuda. 特别注意：如果系统重启之后出现重复登录的情况，多数情况下都是安装了错误版本的显卡驱动。需要下载对应本身机器安装的显卡版本。 3.安装CUDA1.卸载旧的CUDA 这是因为如果您的显卡RTX2080，安装了CUDA 8.0 和 CUDNN 7.0.5或者CUDA9.0不能够正常使用，需要安装CUDA 10.0 和 CUDNN 7.4.2，所以要先卸载原来的CUDA。注意以下的命令都是在root用户下操作的。 卸载CUDA很简单，主要执行的是CUDA自带的卸载脚本，请根据自己的cuda版本找到卸载脚本： 如果之前安装了CUDA 9.0在 /usr/local/cuda-9.0/bin 目录下有一个 uninstall_cuda*.pl 文件，CUDA8卸载同理，可以直接运行卸载，命令如下： sudo /usr/local/cuda-9.0/bin/uninstall_cuda_9.0.pl 卸载之后，还有一些残留的文件夹，如果之前安装的是CUDA 9.0，可以一并删除： sudo rm -r /usr/local/cuda-9.0/ 这样即可将 CUDA 全部卸载。 2.安装CUDA 安装的CUDA10.0和CUDNN7.4.2版本： 接下来的安装步骤都是在root用户下操作的。 下载和安装CUDA 我们可以在官网：CUDA10下载页面，下载符合自己系统版本的CUDA。 cd 到下载的文件目录.run文件下，root下安装 sudo chmod +x cuda_10.0.130_410.48_linux.run // 获取权限 sudo sh cuda_10.0.130_410.48_linux.run // 执行安装包，开始安装 开始安装之后，需要阅读说明，可以使用Ctrl + C直接阅读完成，或者使用空格键慢慢阅读。然后进行配置，这里说明一下： 注意：为了避免问题，不要选择安装CUDA下的显卡驱动，其他选yes （是否同意条款，必须同意才能继续安装） accept/decline/quit: accept （这里不要安装驱动，因为已经安装最新的驱动了，否则可能会安装旧版本的显卡驱动，导致重复登录的情况） Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 410.48? (y)es/(n)o/(q)uit: n Install the CUDA 10.0 Toolkit?（是否安装CUDA 10 ，这里必须要安装） (y)es/(n)o/(q)uit: y Enter Toolkit Location（安装路径，使用默认，直接回车就行） [ default is /usr/local/cuda-10.0 ]: Do you want to install a symbolic link at /usr/local/cuda?（同意创建软链接） (y)es/(n)o/(q)uit: y Install the CUDA 10.0 Samples?（不用安装测试，本身就有了） (y)es/(n)o/(q)uit: n Installing the CUDA Toolkit in /usr/local/cuda-10.0 ...（开始安装） 安装完成之后，可以配置他们的环境变量，打开.bashrc 文件： sudo gedit ~/.bashrc 打开文件后将下面代码加入文件最后，cuda位置，要根据自己cuda版本安装路径: export CUDA_HOME=/usr/local/cuda-10.0 export LD_LIBRARY_PATH=${CUDA_HOME}/lib64:${LDLIBRARY_PATH} export PATH=${CUDA_HOME}/bin:${PATH} 保存 关闭，命令行输入,使配置生效： source ~/.bashrc 终端输入： nvcc --version 或 nvcc -V 会输出CUDA的版本信息，cuda安装成功。 4.下载和安装cuDNN1.官网下载：https://developer.nvidia.com/rdp/cudnn-download进入时需要登录，没有账户的话就注册一个，进入即可。选择和自己cuda适配的版本。 2.解压下载好的cudnn压缩包，如： cudnn-10.0-linux-x64-v7.4.2.24.tgz 或者 cudnn-10.0-linux_x64-v7.6.0.64.tgz tar -zxvf cudnn-10.0-linux-x64-v7.4.2.24.tgz 解压之后可以得到以下文件： cuda/include/cudnn.h cuda/NVIDIA_SLA_cuDNN_Support.txt cuda/lib64/libcudnn.so cuda/lib64/libcudnn.so.7 cuda/lib64/libcudnn.so.7.4.2 cuda/lib64/libcudnn_static.a 使用以下命令复制这些文件到CUDA目录下： sudo cp cuda/include/cudnn.h /usr/local/cuda-10.0/include/ sudo cp cuda/lib64/libcudnn* /usr/local/cuda-10.0/lib64/ sudo chmod a+r /usr/local/cuda-10.0/include/cudnn.h sudo chmod a+r /usr/local/cuda-10.0/lib64/libcudnn* 3.查看cudnn版本，可以使用以下命令查看CUDNN的版本信息 cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2 安装好cuda和cudnn之后，恭喜你，就可以安装tensorflow、pytorch等深度学习框架了。 5.安装Anaconda3这里使用 Anaconda 3 来安装，下载地址：https://www.anaconda.com/download/#linux，点击 Download 按钮下载即可，这里下载的是 Anaconda 3-5.1 版本，如果下载速度过慢,强烈建议选择使用清华镜像 。 下载下来之后目录下会出现一个 Anaconda3-5.1.0-Linux-x86_64.sh 文件，然后直接执行即可安装： bash Anaconda3-5.1.0-Linux-x86_64.sh 执行完毕之后按照默认设置走下来即可完成安装。 这里默认它会安装到用户目录下，如果想全局安装，可以在这一步输入你要安装的地址： Anaconda3 will now be installed into this location: /home/wy/anaconda3 - Press ENTER to confirm the location - Press CTRL-C to abort the installation - Or specify a different location below [/home/wy/anaconda3] >>> /usr/local/anaconda3 PREFIX=/usr/local/anaconda3 这里我指定了将其安装到 /usr/local/anaconda3 目录下，全局安装，所有用户共享，当然如果只想本用户使用的话使用默认配置即可。 安装完成之后添加 python3 和 pip3 的软链接： sudo ln -s /usr/local/anaconda3/bin/python3 /usr/local/sbin/python3 sudo ln -s /usr/local/anaconda3/bin/pip /usr/local/sbin/pip3 这里是将软连接其添加到 /usr/local/sbin 目录下了，它默认会存在于环境变量中，因此可以直接调用。 当然也可以选择把 /usr/local/anaconda3/bin 目录添加到环境变量中，具体地，可以修改 ~/.bashrc 文件，添加如下内容： export PATH=/usr/local/anaconda3/bin${PATH:+:${PATH}} 然后执行： source ~/.bashrc 即可生效，下次登录时也会默认执行 ~/.bashrc 文件，也会生效。 接下来我们验证下 python3、pip3 命令是否都来自 Anaconda，命令如下： pip3 -V pip 9.0.1 from /usr/local/anaconda3/lib/python3.6/site-packages (python 3.6) which python3 /usr/local/anaconda3/bin/python3 python3 Python 3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) [GCC 7.2.0] on linux Type "help", "copyright", "credits" or "license" for more information. >>> 如果输入 pip3 和 python3 命令能出现如上类似结果，路径都在 /usr/local/anaconda3，就证明 Python 3 安装成功了。 6.安装TensorFlow 1.8到现在为止 Python 3.6、CUDA 10.0 和 cuDNN 7.14就已经安装好了，而且环境变量也配置好了，接下来我们直接安装 TensorFlow 1.8 即可。 这里需要安装的是 TensorFlow 的 GPU 版本，命令如下： pip3 install tensorflow-gpu==1.8.0 你会发现上面安装特别慢，强烈建议使用 国内pypi源加速 , 速度超快啊！！！ pip3 install tensorflow-gpu==1.8.0 -i https://pypi.tuna.tsinghua.edu.cn/simple 安装完成之后验证一下： python import tensorflow as tf tf.__version__ tf.__path__ 如果没有报错，那就证明全部环境配置都成功了。 如果您的tensorflow安装后不能使用，请考虑tensorflow版本和CUDA、cuDNN版本的兼容问题，请自行百度, 也可参考本博文下方链接。 7.Pytorch 1.2安装过程中注意：torch和torchvision版本相匹配 如不匹配，可能报错： torchvision 0.3.0 has requirement torch>=1.1.0, but you'll have torch 1.0.0 which is incompatible. RTX 2080Ti，CUDA安装版本10及以上， 方案一： 通过pytorch官发链接pip装，命令如下： pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.0-cp36-cp36m-linux_x86_64.whl 发现速度实在太慢！！于是我们考虑 方案二： 离线安装： 注意方案一 在控制台出现的下载路径，复制到浏览器，手动下载： 到官网下载torch1.1：https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl ，将本地文件上传到服务器指定位置，路径换到压缩包所在位置，在控制台输入指令： pip3 install torch-1.1.0-cp36-cp36m-linux_x86_64.whl pip3 install torchvision==0.3.0 方案三： 以上两种方案纯属呵呵🙂，强烈建议使用 国内pypi源加速 , 直接安装pytorch最新版本，最新版本做了诸多优化！通过pypi镜像安装速度超快啊 ★★★★★ pip3 install torch torchvision -i https://pypi.tuna.tsinghua.edu.cn/simple 这样就安装好啦，然后测试一下, 会输出torch版本1.2.0，torchvision版本0.4.0： python import torch,torchvision torch.__version__ torchvision.__version__ torch.__path__ torchvision.__path__ 以上便是 Ubuntu 16.04 + RTX 2080 Ti + Python 3.6 + CUDA 10.0 + cuDNN 7.4 + TensorFlow 1.8 + Pytorch 1.2等 完整环境配置过程。 他山之石： Ubuntu下安装CUDA10.0遇到的问题（一定要注意自己版本） Tensorflow不同版本要求与CUDA及cuDNN版本对应关系 ubuntu 18.04 安装后基本配置以及常用软件安装 深度学习工程师生存指南]]></content>
      <categories>
        <category>深度学习环境搭建</category>
      </categories>
      <tags>
        <tag>深度学习环境搭建</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[科研工具]]></title>
    <url>%2F2019%2F08%2F27%2Fke-yan-gong-ju%2F</url>
    <content type="text"><![CDATA[Some tips for research and coding本博文正在丰富内容～～～😄 1. 科研起步必读文章 1.Karpathy-博士经验 (翻译) 重点 2.陈天奇-科研十年 3.王一-科研idea 4.王赟-我的八年博士生涯 5.李沐-博士这五年 6.毕业撒花 7.帝国理工-博士手册（Doctoral Milestones） 信息收集 1.Google Scholar 如何查询相关文章 2.Google Scholar 如何follow研究者 谷歌学术：https://www.google.com.hk 谷歌学术镜像：http://xilesou.99lb.net/ 、 https://xue.glgoo.org/ 3.计算机相关论文免翻墙直连检索DBLP 也可通过 https://dblp.uni-trier.de/ 访问. 4.arXiv预印本 http://arxiv.org/list/cs.CV/recent 看最近一周的论文; 使用http://arxiv.org/list/cs.CV/1704，可以查看17年04月的全部内容了; 使用http://arxiv.org/list/cs.CV/17，可以查看17年的所有内容，其余搜索也类似。 5.arXiv中国镜像 使用技巧：如 https://arxiv.org/pdf/1512.03385.pdf 下载很慢，换成 http://xxx.itp.ac.cn/pdf/1512.03385.pdf, 即可体验光速下载。注意 https 要换成 http 6.语义学者(Semantic Scholar)免费学术搜索引擎 7.arXiv-sanity人工智能论文检索引擎 8.arXiv-vanity将来自 arXiv 的论文渲染成响应式网页 9.arXiv链接中科院文献情报中心开发的arXiv文献检索平台 10.Papers With Code 自动把论文连接到实现代码的 GitHub 资源库和数据集，并根据 GitHub 的收藏量排序。每篇论文可能有多个合并的条目，可快速了解领域进展。 11.IEEE会议或期刊论文检索 12.sci-hub文献下载站 例如输入这个：https://ieeexplore.ieee.org/document/8070331/ 13.论文在线翻译网页-通天塔 14.2019-2020 International Conferences in Artificial Intelligence, Machine Learning, Computer Vision, Data Mining, Natural Language Processing and Robotics 15.mendeley 文章整理APP 科研必备的浏览器插件+文献工具：链接：https://pan.baidu.com/s/1w2Xa30hOvo1aMhpiJCmceg 提取码：7j6b TeXstudio + TeX Live论文撰写工具礼包：链接：https://pan.baidu.com/share/init?surl=5dYyDflQCPVz_jlwEkngUw 提取码：hz3r 16.2019 CVPR Accepted Papers分类检索 17.深度学习500问 18.深度学习工程师生存指南 👍 其他 1.蓝灯 邀请码 Y238YKH 2.旋风 APP 2. Github Github历史和目的 创建账号 建立Repository git init 初始化 git add xxx.txt 添加xxx.txt到git git add -A 添加所有文件到git git commit -m “hahahah” 添加注释 git push 上传更新 git clone https://github.com/account/repository.git git status 查询状态 如何在网站上修改 git pull 与Github同步 git branch 查看branch git branch -a 查看所有branch git branch new 创建branch名为new git checkout new 进入new branch git checkout master 返回主branch git checkout -b new2 创建并进入branch名为new2 修改branch后，commit到Github上，如何在github上发起Push Request .gitignore 自定义不能被添加的文件 添加collaborator 新建organization 练习：建立自己的个人主页 3. GPU 目的 nvidia-smi 查看GPU使用情况 watch -n 1 nvidia-smi：每秒钟刷新GPU使用情况 sudo fuser -v /dev/nvidia* 查看GPU使用者 sudo kill -9 PID 杀掉进程 CUDA_VISIBLE_DEVICES=0 python xxx.py 指定GPU0 CUDA_VISIBLE_DEVICES=0,1 python xxx.py 指定GPU0和1 CUDA_VISIBLE_DEVICES=“” python xxx.py 不使用GPU python xxx.py &gt; train.log &amp; 把输出放入train.log（&gt;）; 不显示输出（&amp;） CPU &amp; GPU top htop 深度学习GPU环境搭建全家桶 4. Screen 目的：关闭当前Terminal/命令窗口，程序依然进行。 screen -S name 创建screen，并进入 screen -ls 查看screen列表 screen -r name 进入screen ctrl+A+D 退出当前screen screen -d name 关闭screen screen -X -S name kill 删除screen 5. Virtualenv 目的 Installation pip3 install virtualenv 安装virtualenv virtualenv env 新建环境 source env/bin/activate 进入环境 deactivate 退出环境 6. 文档 Markdown Typora Readthedoc https://github.com/tensorlayer/tensorlayer/tree/master/docs https://tensorlayer.readthedocs.io RST and Sphinx syntax 7. 远程连接 MacOS - Cyberduck Windows - MobaXterm PyCharm TeamViewer 8. TensorLayer Installation Dynamic and Static Models 、 Advanced Features 、 Data Augmentation Basic Tutorials CIFAR10 has data augmentation A Good Project Template RL Tutorials for Research / for Production PyTorch深度网络逐层性能分析器 9. Deep Learning 等 NIPS 19 Subject Areas CVPR 19 Program Guide CVPR 19 Paper list / oral list SIGGRAPH 19 Technical Papers Fast Forward/ Paper List zsdonghao/deep-learning-note Distributed Training TingFlow 教学性DL框架 模型结构可视化神器 - Netron 线Netron网址: https://lutzroeder.github.io/netron/ 10. Publishing Paper Conference DDL Grammarly 查语法错误 Overleaf 协同编辑 LaTeX: MacTex TeXLive + TexStudio等软件资源站点 Best tool for using LaTeX locally: VSCode + LaTeX Workshop]]></content>
      <categories>
        <category>科研工具</category>
      </categories>
      <tags>
        <tag>科研工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习GPU环境搭建-上篇]]></title>
    <url>%2F2019%2F08%2F26%2Fshen-du-xue-xi-gpu-huan-jing-da-jian-shang-pian%2F</url>
    <content type="text"><![CDATA[为了加速神经网络的训练，使用CPU训练速度很慢，所以使用CUDA和cuDNN对神经网络进行加速，在配置的过程中你会遇到很多坑，各种坑，网上也有很多教程但是实现起来各种ERROR，真心觉得累，经过多次实验做如下超全总结！！！ 本节详细说明一下深度学习环境配置，深度学习GPU环境搭建全家桶 注意：RTX 2080 Ti显卡的环境安装过程略有不同，RTX 2080Ti，CUDA要安装10以上，请参考下篇博文。 Python 3.6首先安装 Python 3.6，这里使用 Anaconda 3 来安装，下载地址：https://www.anaconda.com/download/#linux，点击 Download 按钮下载即可，这里下载的是 Anaconda 3-5.1 版本，如果下载速度过慢,强烈建议选择使用清华镜像 。 下载下来之后目录下会出现一个 Anaconda3-5.1.0-Linux-x86_64.sh 文件，然后直接执行即可安装： bash Anaconda3-5.1.0-Linux-x86_64.sh 执行完毕之后按照默认设置走下来即可完成安装。 这里默认它会安装到用户目录下，如果想全局安装，可以在这一步输入你要安装的地址： Anaconda3 will now be installed into this location: /home/wy/anaconda3 - Press ENTER to confirm the location - Press CTRL-C to abort the installation - Or specify a different location below [/home/wy/anaconda3] >>> /usr/local/anaconda3 PREFIX=/usr/local/anaconda3 这里我指定了将其安装到 /usr/local/anaconda3 目录下，全局安装，所有用户共享，当然如果只想本用户使用的话使用默认配置即可。 安装完成之后添加 python3 和 pip3 的软链接： sudo ln -s /usr/local/anaconda3/bin/python3 /usr/local/sbin/python3 sudo ln -s /usr/local/anaconda3/bin/pip /usr/local/sbin/pip3 这里是将软连接其添加到 /usr/local/sbin 目录下了，它默认会存在于环境变量中，因此可以直接调用。 当然也可以选择把 /usr/local/anaconda3/bin 目录添加到环境变量中，具体地，可以修改 ~/.bashrc 文件，添加如下内容： export PATH=/usr/local/anaconda3/bin${PATH:+:${PATH}} 然后执行： source ~/.bashrc 即可生效，下次登录时也会默认执行 ~/.bashrc 文件，也会生效。 接下来我们验证下 python3、pip3 命令是否都来自 Anaconda，命令如下： pip3 -V pip 9.0.1 from /usr/local/anaconda3/lib/python3.6/site-packages (python 3.6) which python3 /usr/local/anaconda3/bin/python3 python3 Python 3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) [GCC 7.2.0] on linux Type "help", "copyright", "credits" or "license" for more information. >>> 如果输入 pip3 和 python3 命令能出现如上类似结果，路径都在 /usr/local/anaconda3，就证明 Python 3 安装成功了。 安装驱动首先查看一下自己的电脑需要怎样的驱动，我们可以先到 http://www.nvidia.com/Download/index.aspx 查询下我们需要的是怎样的驱动，这里我的显卡是 GTX 1080，所以以此为例说明，勾选好对应的配置： 点击 Search，可以看到查询结果如下所示： Version: 390.25 Release Date: 2018.1.29 Operating System: Linux 64-bit Language: English (US) File Size: 77.48 MB 这里说明我们需要的版本是 390.25。 接下来如果我们之前安装了驱动的话，可以重新安装一下，如果当前已经安装好了就不必了。 如果要重装，需要首先卸载掉之前的显卡驱动，以下操作都需要在命令界面操作，执行Ctrl-Alt+F1快捷键进入命令界面: sudo apt-get remove –purge nvidia* 运行之后 NVIDIA 的一些驱动就被卸载了。 这时候 nvidia-smi 等命令已经不能用了，这就证明显卡驱动已经被卸载了。 然后接下来添加一个 PPA 源，命令如下： sudo add-apt-repository ppa:graphics-drivers/ppa 然后更新一下： sudo apt-get update 随后重新安装显卡驱动： sudo apt-get install nvidia-390 注意这里的 390 就是刚才我们查询出来的版本，以实际查询出来的版本为准。 CUDA 9.0如果存在之前的旧版本，可以选择先卸载，以免和新的 CUDA 版本产生冲突，如果之前安装了CUDA 8.0在 /usr/local/cuda-8.0/bin 目录下有一个 uninstall_cuda*.pl 文件，可以直接运行卸载，命令如下： sudo ./uninstall_cuda_*.pl 或 sudo /usr/local/cuda-8.0/bin/uninstall_cuda_8.0.pl 卸载之后，还有一些残留的文件夹，之前安装的是CUDA 8.0，可以一并删除： sudo rm -r /usr/local/cuda-8.0/ 这样即可将 CUDA 全部卸载。 接下来我们再下载 CUDA 9.0，注意 TensorFlow 1.5 和 1.6 版本依然只是兼容 CUDA 9.0，没有兼容 CUDA 9.1，所以不要下载 9.1，CUDA 9.0 的下载地址是：https://developer.nvidia.com/cuda-90-download-archive，然后依次勾选好系统的版本. 这里我们选择 Linux-x86_64-Ubuntu-16.04-runfile 的配置，然后点击 Base Installer 部分的 Download 按钮，下载 CUDA 9.0 安装包。 对应的下载命令是： wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda_9.0.176_384.81_linux-run 执行此命令，等待下载完成即可。 接下来执行安装，运行如下命令： sudo bash cuda_9.0.176_384.81_linux-run 安装过程需要输入一些确认选项，过程如下： Description The NVIDIA CUDA Toolkit provides command-line and graphical tools for building, debugging and optimizing the performance Do you accept the previously read EULA? （是否同意条款，必须同意才能继续安装） accept/decline/quit: accept （这里不要安装驱动，因为已经安装最新的驱动了，否则可能会安装旧版本的显卡驱动，导致重复登录） Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 384.81? (y)es/(n)o/(q)uit: n Install the CUDA 9.0 Toolkit? （是否安装CUDA 9 ，这里必须要安装） (y)es/(n)o/(q)uit: y Enter Toolkit Location （安装路径，使用默认，直接回车就行） [ default is /usr/local/cuda-9.0 ]: Do you want to install a symbolic link at /usr/local/cuda? （同意创建软链接） (y)es/(n)o/(q)uit: y Install the CUDA 9.0 Samples? （安装测试） (y)es/(n)o/(q)uit: y Enter CUDA Samples Location （安装路径，使用默认，直接回车就行） [ default is /home/cqc ]: Installing the CUDA Toolkit in /usr/local/cuda-9.0 ... （开始安装） 最后如果出现这样的提示，就证明 CUDA 安装好了： Driver: Not Selected Toolkit: Installed in /usr/local/cuda-9.0 Samples: Installed in /home/cqc, but missing recommended libraries Please make sure that - PATH includes /usr/local/cuda-9.0/bin - LD_LIBRARY_PATH includes /usr/local/cuda-9.0/lib64, or, add /usr/local/cuda-9.0/lib64 to /etc/ld.so.conf and run ldconfig as root To uninstall the CUDA Toolkit, run the uninstall script in /usr/local/cuda-9.0/bin Please see CUDA_Installation_Guide_Linux.pdf in /usr/local/cuda-9.0/doc/pdf for detailed information on setting up CUDA. ***WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 384.00 is required for CUDA 9.0 functionality to work. To install the driver using this installer, run the following command, replacing &lt;CudaInstaller> with the name of this run file: sudo &lt;CudaInstaller>.run -silent -driver 然后我们需要配置一下环境变量，更改 ~/.bashrc 文件，添加如下几行： export PATH=/usr/local/cuda/bin${PATH:+:${PATH}} export LD_LIBRARY_PATH=/usr/local/cuda/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}} export CUDA_HOME=/usr/local/cuda 修改完毕之后执行一下使其生效： source ~/.bashrc 这时我们输出 CUDA_HOME、LD_LIBRARY_PATH 就可以看到对应的输出了： echo $CUDA_HOME /usr/local/cuda echo $LD_LIBRARY_PATH /usr/local/cuda/lib64 nvcc -V 或者： nvidia-smi 这样就代表环境变量生效了，CUDA 安装完成。 cuDNN 7.1cuDNN 的全称是 The NVIDIA CUDA® Deep Neural Network library，是专门用来对深度学习加速的库，它支持 Caffe2, MATLAB, Microsoft Cognitive Toolkit, TensorFlow, Theano 及 PyTorch 等深度学习的加速优化，目前最新版本是 cuDNN 7.1，接下来我们来看下它的安装方式。 下载链接：https://developer.nvidia.com/rdp/cudnn-download，或者 cuDNN Download 需要注册之后才能打开，这里我们选择 cuDNN v7.1.1 (Feb 28, 2018), for CUDA 9.0，然后选择 cuDNN v7.1.1 Library for Linux： 下载下来之后解压安装即可： tar -zxvf cudnn-9.0-linux-x64-v7.1.tgz sudo cp cuda/include/cudnn.h /usr/local/cuda/include/ sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64/ -d sudo chmod a+r /usr/local/cuda/include/cudnn.h sudo chmod a+r /usr/local/cuda/lib64/libcudnn* 执行完如上命令之后，cuDNN 就安装好了，这时我们可以发现在 /usr/local/cuda/include 目录下就多了 cudnn.h 头文件。 ubuntu16.04查看CUDA和cuDNN版本cuda版本查看: cat /usr/local/cuda/version.txt cudnn版本查看: cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2 TensorFlow 1.8到现在为止 Python 3.6、CUDA 9.0 和 cuDNN 7.1 就已经安装好了，而且环境变量也配置好了，接下来我们直接安装 TensorFlow 1.8 即可，TensorFlow 1.8 版本针对 CUDA 9 和 cuDNN 7 做了优化，可以预构建二进制文件。 这里需要安装的是 TensorFlow 的 GPU 版本，命令如下： pip3 install tensorflow-gpu==1.8.0 你会发现上面安装特别慢，强烈建议使用 国内pypi源加速 , 速度超快啊！！！ pip3 install tensorflow-gpu==1.8.0 -i https://pypi.tuna.tsinghua.edu.cn/simple 安装完成之后验证一下： python import tensorflow as tf tf.__version__ tf.__path__ 如果没有报错，那就证明全部环境配置都成功了。 如果您的tensorflow安装后不能使用，请考虑tensorflow版本和CUDA、cuDNN版本的兼容问题，请自行百度，也可参考本博文下方链接。。 Pytorch 1.1pytorch官网：https://pytorch.org/ 打开官网，可以按照选择安装方式（pip , conda, source）和 python版本，cuda版本来进行安装，由于特殊的网络国情，一般是打不开，或者是无法查看 run the command 之后的指令的。 你会发现上面安装特别慢，强烈建议使用 国内pypi源加速 , 速度超快啊！！！ pip3 install torch==1.1.0 torchvision==0.3.0 -i https://pypi.tuna.tsinghua.edu.cn/simple 如果已经安装torch，仅仅想更新环境，pip升级torch命令如下，注意，如果不像上面指定版本，将更到最新版本！： pip3 install --upgrade torch torchvision -i https://pypi.tuna.tsinghua.edu.cn/simple 安装pytorch命令合集. 配置 ssh 远程连接1）安装 open-ssh apt-get install openssh-server 2）修改权限，允许 ssh 登录 root gedit /etc/ssh/sshd_config 注释 ：PermitRootLogin prohibit-password添加： PermitRootLogin yes 3）重启 ssh service ssh restart 设置Ubuntu 16.04 允许进行远程控制请参考 VNC实现Windows远程访问Ubuntu 16.04（无需安装第三方桌面,直接使用自带远程工具） . Windows全能终端神器MobaXterm安装主要功能： 支持各种连接SSH，X11，RDP，VNC，FTP，MOSH支持Unix命令（bash，ls，cat，sed，grep，awk，rsync，…）连接SSH终端后支持SFTP传输文件各种丰富的插件（git/dig/aria2…）可运行Windows或软件 官网下载地址 No module named ‘cv2’等python库解决方法只要是缺少的python库文件，请善用 国内pypi源加速 , 速度超快啊！！！ pip3 install opencv-python -i https://pypi.tuna.tsinghua.edu.cn/simple Python包更新方法当你需要更新python包时，还是那句话，请善用 国内pypi源加速 , 速度超快啊！！！ 如：我当前需要更新pip pip install --upgrade pip -i https://pypi.tuna.tsinghua.edu.cn/simple Ubuntu下python开发IDE专业版Pycharm的安装请自行百度，可参考 https://blog.csdn.net/CAU_Ayao/article/details/80578600 进行安装。 Ubuntu下Markdown编辑器Typora的安装 一个优雅的markdown编辑器，支持mac，windows，linux全平台，是一款支持实时预览的 Markdown 文本编辑器 ，完全免费。 官方下载地址 | 史上最完美的 Typora 教程 TeamViewer 远程控制桌面工具安装 TeamViewer主要是用来连实验室的电脑，也可以用用 AnyDesk, 两个都是全平台的. 1.官网下载安装包 网址：https://www.teamviewer.com/cn/download/linux/下载amd64版本 2.安装 sudo dpkg -i teamviewer_14.1.3399_amd64.deb 3.问题解决 可能存在依赖问题，安装不了，终端输入： sudo apt install -f 重新输入： sudo dpkg -i teamviewer_14.1.3399_amd64.deb 问题解决！ 以上便是 Ubuntu 16.04 + Nvidia GTX 1080 + Python 3.6 + CUDA 9.0 + cuDNN 7.1 + TensorFlow 1.8 + Pytorch 1.1 + ssh远程连接设置+ Ubunt桌面远程控制等 完整环境配置过程。 注意：RTX 2080 Ti显卡的环境安装过程略有不同，RTX 2080Ti，CUDA要安装10以上。 当您程序报错： THCudaCheck FAIL file=/pytorch/aten/src/THC/THCGeneral.cpp line=405 error=11 : invalid argument 原因：显卡用的RTX 2080Ti，CUDA就要装10以上， 方案一： 通过pytorch官发链接pip装，命令如下： pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.0-cp36-cp36m-linux_x86_64.whl 发现速度实在太慢！！于是我们考虑 方案二： 离线安装： 注意方案一 在控制台出现的下载路径，复制到浏览器，手动下载： 如，到指定路径下载torch1.0：https://download.pytorch.org/whl/cu100/torch-1.0.0-cp36-cp36m-linux_x86_64.whl ，将本地文件上传到服务器指定位置，路径换到压缩包所在位置，在控制台输入指令： pip3 install torch-1.0.0-cp36-cp36m-linux_x86_64.whl pip3 install torchvision==0.2.1 方案三： 以上两种方案纯属呵呵🙂，强烈建议使用 国内pypi源加速 , 直接安装pytorch最新版本，最新版本做了诸多优化！通过pypi镜像安装速度超快啊 ★★★★★ pip3 install torch torchvision -i https://pypi.tuna.tsinghua.edu.cn/simple 这样就安装好啦，然后测试一下，会输出torch版本1.2.0，torchvision版本0.4.0： python import torch,torchvision torch.__version__ torchvision.__version__ torch.__path__ torchvision.__path__ RTX 2080Ti，CUDA要安装10以上，否则报错，原因详见： https://discuss.pytorch.org/t/cuda-runtime-error-11/30080/13 https://github.com/pytorch/pytorch/issues/15797#issuecomment-452021037 国内常见的pypi源清华：https://pypi.tuna.tsinghua.edu.cn/simple 阿里云：http://mirrors.aliyun.com/pypi/simple/ 中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/ 华中理工大学：http://pypi.hustunique.com/ 山东理工大学：http://pypi.sdutlinux.org/ 豆瓣：http://pypi.douban.com/simple/ 他山之石： Ubuntu下安装CUDA10.0遇到的问题（一定要注意自己版本） tensorflow各个版本的CUDA以及Cudnn版本对应关系 Tensorflow不同版本要求与CUDA及CUDNN版本对应关系 Ubuntu16.04 安装python3.6和相应的pip3 pytorch1.0]]></content>
      <categories>
        <category>深度学习环境搭建</category>
      </categories>
      <tags>
        <tag>深度学习环境搭建</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo 博客搭建指南]]></title>
    <url>%2F2019%2F08%2F24%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new "My New Post" More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment Hexo的简洁、神秘让我跃跃欲试，在使用过程中遇到了很多问题，整理此文，一是方便其他技术人搭建自己的博客，二是给自己的学习之旅做个总结。 Hexo 有两份主要的配置文件（_config.yml），一份位于站点根目录下，另一份位于主题目录下。为了描述方便，在以下说明中，将前者称为站点配置文件，后者称为主题配置文件。 1 Hexo介绍Hexo是基于NodeJs的静态博客框架，简单、轻量，其生成的静态网页可以托管在Github和Heroku上。 超快速度 支持MarkDown 一键部署 丰富的插件 下面以我的博客为例，xiaoming.github.io 2 环境准备2.0 安装gitGit for Windows, 这里提供一个国内的下载站，方便网友下载，然后选择安装目录后，一直next就可以。https://github.com/waylau/git-for-win 2.1 安装node.js去nodejs官网下载对应系统的安装包，然后一直一直next安装。 检验安装成功： $ node -v 2.2 安装hexo$ npm install hexo-cli -g 注意：Mac系统，则需要 $ sudo npm install hexo-cli -g 3 利用Hexo搭建一个博客3.1 创建博客目录xiaoming.github.io$ hexo init xiaoming.github.io $ cd xiaoming.github.io $ npm install 3.2 生成静态页面$ hexo clean $ hexo g g 即generate 3.3 运行$ hexo s s 即server 然后打开浏览器，输入地址 localhost:4000 即可看到效果 4 发一篇文章试试4.1 命令方式$ hexo new test 此时会在source/_posts目录下生成test.md文件，输入些许内容，然后保存. 生成下，看看效果 $ hexo clean $ hexo g $ hexo s 访问 localhost:4000 即可 4.2 直接方式在 source/_posts/下新建一个.md文件也可 5 配置网站的设置大部分都在_config.yml文件中，详细配置可以查看官方文档 下面只列出简单常用配置 title -&gt; 网站标题 subtitle -&gt; 网站副标题 description -&gt; 网站描述 author -&gt; 您的名字 language -&gt; 网站使用的语言 坑：进行配置时，需要在冒号:后加一个英文空格 title: xiaoming6 换一个好看的主题Hexo 中有很多主题，可以在官网查看。这里我推荐hexo-theme-next，下面列举更换主题的一般套路： 6.1 下载主题资源$ git clone https://github.com/iissnan/hexo-theme-next themes/next 克隆新地址： $ git clone https://github.com/theme-next/hexo-theme-next themes/next 6.2 应用下载的主题在网站配置文件_config.yml中，配置theme theme: next next是主题名称，具体的可查看主题的文档 6.3 主题其他配置可在/theme/{theme}/_config.yml 主题的配置文件下进行主题的配置。 接下来，可以执行万能的调试命令看看效果 $ hexo clean $ hexo g #g 是 generate 缩写:生成，d 是 deploy 缩写:部署 $ hexo s #s 是 serverce 缩写:启动服务预览 7 部署到Github7.1 有个github账号xiaoming7.2 创建一个xiaoming.github.io的public仓库如果您的账户名是xiaoming,则需要创建一个xiaoming.github.io的public仓库. 7.3 安装 hexo-deployer-git$ npm install hexo-deployer-git --save 7.4 网站配置git在网站的_config.yml中配置deploy deploy: type: git repo: &lt;repository url&gt; branch: [branch] branch为分支，默认为master,可以不配置repo为仓库地址，在github上新建仓库后，可复制此地址 7.5 部署$ hexo d d 即deploy 8 贴标签，方便搜索8.1 两个确认 确认站点配置文件有 tag_dir: tags 确认主题配置文件有 tags: tags8.2 新建tags页面1&gt;运行以下命令 $ hexo new page tags 此时会在source/下生成tags/index.md文件 2&gt;修改/source/tags目录下的index.md文件 title: tags date: 2015-10-20 06:49:50 type: &quot;tags&quot; comments: false date 可保持系统生成的时间， type: &quot;tags&quot; comments: false很重要 3&gt;修改主题配置文件去掉tags的注释 menu: home: / #主页 categories: /categories #分类页（需手动创建） #about: /about #关于页面（需手动创建） archives: /archives #归档页 tags: /tags #标签页（需手动创建） #commonweal: /404.html #公益 404 （需手动创建）8.3 在文章中添加tags在文章xx.md中添加： tags: - Tag1 - Tag2 - Tag3多个Tag可按上面的格式添加。 其文件头部类似： title: TagEditText date: 2016-11-19 10:44:25 tags: - Tag1 - Tag2 - Tag39 分类，给文章归档9.1 两个确认 确认站点配置文件打开了 category_dir: categories 确认主题配置文件打开了 categories: /categories9.2 新建categories文件1&gt;运行以下命令 $ hexo new page categories 此时会在source目录下生成categories/index.md文件 2&gt;修改/source/categories目录下的index.md文件 title: categories date: 2015-10-20 06:49:50 type: &quot;categories&quot; comments: false date 可保持系统生成的时间， type: &quot;categories&quot; comments: false很重要 3&gt;修改主题配置文件去掉categories的注释 menu: home: / #主页 categories: /categories #分类页（需手动创建） #about: /about #关于页面（需手动创建） archives: /archives #归档页 tags: /tags #标签页（需手动创建） #commonweal: /404.html #公益 404 （需手动创建）9.3 在文章中添加categories在文章xx.md中添加： categories: - cate其文件头部类似： title: TagEditText date: 2016-11-19 10:44:25 categories: - cate10 hexo修改文章底部的那个带#号的标签实现效果图 具体实现方法: 修改模板 /themes/next/layout/_macro/post.swig，搜索 rel=&quot;tag&quot;&gt;# 或者 rel=&quot;tag&quot;&gt; ，将 # 或者 换成&lt;i class=&quot;fa fa-tag&quot;&gt;&lt;/i&gt; 11 Hexo文章置顶的方法1&gt; 安装插件: npm uninstall hexo-generator-index --save npm install hexo-generator-index-pin-top --save 然后在需要置顶的文章的Front-matter中加上top即可： title: 2019 date: 2019-02-14 16:10:03 top: 1 或者在需要置顶的文章的Front-matter中加上top: true亦可。比如下面这样： title: hexo博客置顶 date: 2017-09-08 12:00:25 categories: 博客搭建系列 top: true 到目前为止，置顶功能已经可以实现了。 2&gt;设置置顶标志: 打开：/blog/themes/next/layout/_macro 目录下的post.swig文件，定位到&lt;div class=&quot;post-meta&quot;&gt;标签下，紧接着下一行插入如下代码： {% if post.top %} &lt;i class="fa fa-thumb-tack">&lt;/i> &lt;font color="7D26CD">置顶&lt;/font> &lt;span class="post-meta-divider">|&lt;/span> {% endif %} Hexo常用命令$ hexo n "博客名称" => hexo new "博客名称" #这两个都是创建新文章，前者是简写模式 $ hexo p => hexo publish $ hexo g => hexo generate #生成 $ hexo s => hexo server #启动服务预览 $ hexo d => hexo deploy #部署 关于hexo的服务器命令: $ hexo server #Hexo 会监视文件变动并自动更新，无须重启服务器。 $ hexo server -s #静态模式 $ hexo server -p 5000 #更改端口 $ hexo server -i 192.168.1.1 #自定义IP $ hexo clean #清除缓存，网页正常情况下可以忽略此条命令 $ hexo g #生成静态网页 $ hexo d #开始部署 hexo资料网站: https://hexo.io/zh-cn/]]></content>
      <categories>
        <category>前端 - 创建博客</category>
      </categories>
      <tags>
        <tag>搭建博客</tag>
      </tags>
  </entry>
</search>
